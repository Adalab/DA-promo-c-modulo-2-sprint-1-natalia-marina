{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PAIR PROGRAMMING PANDAS V\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio pondremos en práctica los conceptos básicos para juntar varios csv que compartan información.\n",
    "\n",
    "Trabajaremos con tres ficheros diferentes:\n",
    "\n",
    "- El csv que creamos en el ejercicio de pair programming Pandas IV, dónde recordamos eliminamos ciertas columnas que no eran necesarias, y habíamos creado nuevas.\n",
    "- El csv llamado attacks_historico donde tenemos información sobre los ataques de tiburón previos al año 1800, este fichero lo tenéis un poco mas abajo para descargar.\n",
    "- El csv llamado attacks_adicional donde tenemos información sobre los ataques de tiburón. de nuevo, este fichero lo tenéis abajo para descargar."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El principal objetivo de este ejercicio de pair programming es acabar teniendo un único DataFrame con toda la información contenida en los tres csv anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerias\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para llevar a cabo nuestro objetivo tendréis que seguir los siguientes pasos:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**EJERCICIO 1**\n",
    "\n",
    "Cargad los tres ficheros nombrados anteriormente y los exploramos para familizarizarnos con ellos y saber que información tienen en común y debatir con tu compañera como podríamos juntar toda la información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos, abrimos y exploramos el archivo guardado del pair de ayer\n",
    "\n",
    "df_attacks3 = pd.read_csv('attacks3.csv')\n",
    "df_attacks3.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attacks3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attacks3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos, abrimos y exploramos el archivo 'attacks_historico'\n",
    "\n",
    "df_historicos = pd.read_csv('attacks_historico.csv')\n",
    "df_historicos.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_historicos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_historicos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos, abrimos y exploramos el archivo 'attacks_adicional'\n",
    "df_adicional = pd.read_csv('attacks_adicional.csv')\n",
    "df_adicional.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adicional.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adicional.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EJERCICIO 2**\n",
    "\n",
    "Chequead que los nombres de las columnas ver si se llaman iguales entre dataframes . ¿Están todas en minúsculas? ¿Tienen espacios? En caso de que no sean todas iguales unificad el nombre de las columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primer DF\n",
    "df_attacks3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos un dict comprehension para modificar todas las columnas del DF, utilizando .lower y .replace\n",
    "# Igual en las celdas de más abajo para los otros dos dataframes\n",
    "\n",
    "columnas_rename = {col :  col.lower().replace(' ', '_') for col in df_attacks3.columns}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attacks3.rename(columns = columnas_rename, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attacks3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segundo DF\n",
    " \n",
    "df_historicos.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_rename2 = {col :  col.lower().replace(' ', '_') for col in df_historicos.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_historicos.rename(columns = columnas_rename2, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_historicos.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tercer DF\n",
    "\n",
    "df_adicional.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_rename3 = {col :  col.lower().replace(' ', '_') for col in df_adicional.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adicional.rename(columns = columnas_rename3, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adicional.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EJERCICIO 3**\n",
    "\n",
    "En este momento nos habremos dado cuenta que el DataFrame que generamos en el pair programming Pandas IV es similar al DataFrame de los datos historicos. Si recordamos, eliminamos algunas columnas en la sesión III que no eran útiles, pero esas columnas están todavía en el histórico. Si no fuera por eso podríamos unir esos dataframes. Realizad los cambios que creais necesarios para que los dataframes sean iguales y luego juntadlos usando el mejor método."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attacks3.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borramos la columna 'unnamed:_0' con el método .drop\n",
    "\n",
    "df_attacks3.drop([\"unnamed:_0\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borramos la columna 'siglo' con el método .drop\n",
    "\n",
    "df_attacks3.drop([\"siglo\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attacks3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attacks3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_historicos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borramos varias columnas a la vez con el método .drop. Las necesarias para poder unir los dataframes\n",
    "# con el método .concat\n",
    "\n",
    "df_historicos.drop([\"unnamed:_0\",\"unnamed:_22\", \"unnamed:_23\", \"case_number.1\", \"case_number.2\", \"href_formula\", \"original_order\", \n",
    "                        \"investigator_or_source\", \"pdf\",], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_historicos.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_historicos.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos la unión de los dataframes con el método .concat\n",
    "\n",
    "df_unidos= pd.concat([df_historicos, df_attacks3], axis = 0, ignore_index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unidos.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unidos.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unidos.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EJERCICIO 4**\n",
    "\n",
    "Es el momento de unir la información de todos los ataques de tiburón que acabamos de crear con el DataFrame de información adicional. Debatid que método es el más correcto para unir toda esta información y ejecutadlo.\n",
    "📌 NOTA Cuando hagáis la unión considerad que la información que más nos interesa es la del DataFrame que creamos en el apartado anterior, lo cual determinará el tipo de unión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adicional.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adicional.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adicional.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adicional.drop('unnamed:_0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adicional.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unidos.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fijamos un índice para poder unir con el método .join\n",
    "\n",
    "df_adicional.set_index('case_number', inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adicional.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos la unión de los dataframes con el método .join\n",
    "\n",
    "df_final= df_unidos.join(df_adicional, on = 'case_number', lsuffix = 'historicos', rsuffix= 'adicional')\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(df_final['case_number'].unique()) para comprobar los case_number"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EJERCICIO 5**\n",
    "\n",
    "Guardad el dataframe nuevo en un csv que usaremos mañana en la clase de pair programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el archivo en la carpeta del pair de hoy\n",
    "\n",
    "df_final.to_csv('attacks5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el archivo en la carpeta del pair de mañana\n",
    "\n",
    "df_final.to_csv('../pandas_VI/attacks5.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "819a5c43c1fad9e35c5b1180124e231b422fc24c453463d400a90e0aae1b9c8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
